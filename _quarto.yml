project:
  type: default
  render:
    - template-computo-python.qmd
    - README.qmd

title: "JAX Ã  la Stan"
subtitle: Bayesian modeling directly in Python
author:
  - name: Brian Ward
    email: bward@flatironinstitute.org
    url: https://brianward.dev
    orcid: 0000-0002-9841-3342
    affiliations:
      - name: Flatiron Institute
        department: Center for Computational Mathematics
        url: https://www.simonsfoundation.org/flatiron/center-for-computational-mathematics/
  - name: Mitzi Morris
    email: mitzi212@gmail.com
    url: https://mitzimorris.github.io
    orcid: 0000-0002-4658-0966
    affiliations:
      - name: Independent Contractor
        department:
        url: https://mitzimorris.github.io
  - name: Andrew Gelman
    email: bward@flatironinstitute.org
    url: https://sites.stat.columbia.edu/gelman/
    orcid: 0000-0002-6975-2601
    affiliations:
      - name: Columbia Univesity
        department: Department of Statistics
        url: https://stat.columbia.edu
      - name: Flatiron Institute
        department: Center for Computational Mathematics
        url: https://www.simonsfoundation.org/flatiron/center-for-computational-mathematics/
  - name: Bob Carpenter
    corresponding: true
    email: bcarpenter@flatironinstitute.org
    url: https://bob-carpenter.github.io
    orcid: 0000-0002-2433-9688
    affiliations:
      - name: Flatiron Institute
        department: Center for Computational Mathematics
        url: https://www.simonsfoundation.org/flatiron/center-for-computational-mathematics/

date: last-modified
date-modified: last-modified
description: |
abstract:
  This paper shows how we can code Bayesian models directly in Python with JAX by following the pattern developed in the Stan probabilistic programming language. This allows a direct, line-by-line translation of all of the courses, texts, and case studies for Stan across the physical, biological, and social sciences, engineering, business, health, education, policy, economics, and sports.  In the general case, a Bayesian model is defined by the joint density of observed data and latent parameters. State-of-the-art algorithms require first or second derivatives of the log density with respect to the parameters. Stan was thus designed to make it easy to code differentiable log densities and generate posterior predictive quantities.  Coupled with modern hardware (e.g., multi-core, GPU, and TPU), compiled JAX far exceeds the efficiency and scalabilty of Stan.  The package ArviZ provides the same posterior analysis tools as Stan, and Blackjax provides a wider range of sampling algorithms.  Thus we can bring all of the benefits of Stan-style model building to modern hardware without sacrificing the benefits of a Python integrated programming environment.
keywords: [JAX, Stan, probabilistic programming, differentiable programming<br /><br />]
bibliography: references.bib
github-user: bob-carpenter
repo: "dj-paper"
draft: true
published: false
license: CC-BY-4.0
format:
  computo-html: default
  computo-pdf: default
jupyter: python3
