project:
  type: default
  render:
    - template-computo-python.qmd
    - README.qmd

title: "JAX Ã  la Stan"
subtitle: Bayesian modeling directly in Python
author:
  - name: Brian Ward
    email: bward@flatironinstitute.org
    url: https://brianward.dev
    orcid: 0000-0002-9841-3342
    affiliations:
      - name: Flatiron Institute
        department: Center for Computational Mathematics
        url: https://www.simonsfoundation.org/flatiron/center-for-computational-mathematics/
  - name: Mitzi Morris
    email: mitzi212@gmail.com
    url: https://mitzimorris.github.io
    orcid: 0000-0002-4658-0966
    affiliations:
      - name: Independent Contractor
        department:
        url: https://mitzimorris.github.io
  - name: Andrew Gelman
    email: bward@flatironinstitute.org
    url: https://sites.stat.columbia.edu/gelman/
    orcid: 0000-0002-6975-2601
    affiliations:
      - name: Columbia Univesity
        department: Department of Statistics
        url: https://stat.columbia.edu
      - name: Flatiron Institute
        department: Center for Computational Mathematics
        url: https://www.simonsfoundation.org/flatiron/center-for-computational-mathematics/
  - name: Bob Carpenter
    corresponding: true
    email: bcarpenter@flatironinstitute.org
    url: https://bob-carpenter.github.io
    orcid: 0000-0002-2433-9688
    affiliations:
      - name: Flatiron Institute
        department: Center for Computational Mathematics
        url: https://www.simonsfoundation.org/flatiron/center-for-computational-mathematics/

date: last-modified
date-modified: last-modified
description: |
abstract:
  We introduce a methodology for coding Bayesian statistical models in Python with JAX that follows the design pattern of the Stan probabilistic programming language.  This allows a direct, line-by-line translation into JAX of all of the courses, texts, and case studies for Stan across the physical, biological, and social sciences, engineering, business, health, education, policy, economics, and sports, as well as providing a transparent framework for further model development.  State-of-the-art algorithms require first or second derivatives of an unnormalized log posterior density. Coupled with modern hardware (e.g., multi-core, GPU, and TPU), compiled JAX far exceeds the efficiency and scalabilty of Stan.  JAX's implementation of NumPy and SciPy, TensorFlow (including TensorFlow Probability), and DeepMind Distrax provide a wider range of special function support than Stan. The package ArviZ provides the same posterior analysis tools as Stan, Blackjax provides a wider range of inference algorithms, and TensorFlow Probability provides a wider range of variable transforms.  Together, these tools provide an environment to code models in the style of Stan for modern hardware without sacrificing the benefits of a Python integrated programming environment.
keywords: [JAX, Stan, probabilistic programming, differentiable programming<br /><br />]
bibliography: references.bib
github-user: bob-carpenter
repo: "dj-paper"
draft: true
published: false
license: CC-BY-4.0
format:
  computo-html: default
  computo-pdf: default
jupyter: python3
